# Flows

## What are flows?

Flows provide a way to quickly create the basic necessary folder structure and set up integrations with several recommended tools for your model development environment.&#x20;

So, once you start working with the Apolo platform, we highly recommend that you create a new flow to ensure that the most important functionality will be accessible right away.

Every flow is based on a template that contains the `.neuro/live.yaml` configuration file for [Apolo Flow Reference](https://app.gitbook.com/o/-MMLX64i1AQdS3ehf2Kg/s/-MMLOF\_FqiWBMcOdY8cj/ "mention") - a tool that simplifies your work process with Apolo. This file guarantees a proper connection between the project structure, the base environment that we provide, and actions with storage and jobs.

## Creating flows

As our flow templates are based on the [**cookiecutter** package](https://github.com/cookiecutter/cookiecutter), you will first need to install it via **pip** or **pipx**:

```
$ pipx install cookiecutter
```

Now, to instantiate a new [flow template](https://github.com/neuro-inc/cookiecutter-neuro-project), run:

```
$ cookiecutter gh:neuro-inc/cookiecutter-neuro-project --checkout release
```

This command will prompt you to enter some info about your new flow:

```
project_name [Neuro Project]: New Cookiecutter Project
project_dir [new-cookiecutter-project]:
project_id [new_cookiecutter_project]:
code_directory [modules]:
preserve Neuro Flow template hints [yes]:
```

{% hint style="info" %}
Default values are indicated by square brackets **\[ ].** You can use them by pressing **Enter**.
{% endhint %}

When you create a new flow, its structure will be as follows:

```
new-cookiecutter-project
├── .github/            <- Github workflows and a dependabot.yml file
├── .neuro/             <- apolo and apolo-flow CLI configuration files
├── config/             <- configuration files for various integrations
├── data/               <- training and testing datasets (we don't keep it under source control)
├── notebooks/          <- Jupyter notebooks
├── modules/            <- models' source code
├── results/            <- training artifacts
├── .gitignore          <- default .gitignore file for a Python ML project
├── .neuro.toml         <- autogenerated config file
├── .neuroignore        <- a file telling Apolo to ignore the results/ folder
├── HELP.md             <- autogenerated template reference
├── README.md           <- autogenerated informational file
├── Dockerfile          <- description of the base image used for your flow
├── apt.txt             <- list of system packages to be installed in the training environment
├── requirements.txt    <- list of Python dependencies to be installed in the training environment
├── setup.cfg           <- linter settings (Python code quality checking)
└── update_actions.py   <- instructions on update actions
```

The internal ID of a flow used by Apolo Flow is generated automatically based on the name of the root folder containing the `.neuro` folder. This can be changed by placing a `project.yml` file with the desired flow ID attribute into the `.neuro` folder. Feel free to refer to the [Apolo Flow Reference](https://app.gitbook.com/o/-MMLX64i1AQdS3ehf2Kg/s/-MMLOF\_FqiWBMcOdY8cj/ "mention") for more information.

## Flow modes

Apolo Flow provides two modes of automating and simplifying your work process while working in a flow - **live** mode and **batch** mode.&#x20;

### Live mode

Live mode allows to execute sets of job definitions that create independent jobs in the Apolo cloud.&#x20;

A job or set of jobs executed in live mode is called a **live job**.

You can learn more about live jobs in the [Live workflows](https://app.gitbook.com/s/-MMLOF\_FqiWBMcOdY8cj/#live-workflows "mention").

### Batch mode

Batch mode serves to orchestrate sets of remote tasks that depend on each other. This is achieved by having a main job that manages the overall workflow by spawning all required sub-jobs, waiting for their results, and starting dependent tasks when all of their requirements are satisfied.&#x20;

A single execution of a set of jobs in batch mode is called a **bake**.

You can learn more about the batch mode in the [Batch workflows](https://app.gitbook.com/s/-MMLOF\_FqiWBMcOdY8cj/#batch-workflows "mention").

## Monitoring flows

You can monitor your flows both via the CLI and in the Apolo Console.

{% tabs %}
{% tab title="CLI" %}
### Monitoring live jobs

To see a list of live jobs on the current flow, their IDs, statuses, and starting times, run the following command:

```
$ apolo-flow ps

  JOB          │ STATUS    │ RAW ID                                   │ WHEN
╶──────────────┼───────────┼──────────────────────────────────────────┼────────╴
  filebrowser  │ unknown   │ N/A                                      │ N/A
  jupyter      │ unknown   │ N/A                                      │ N/A
  multitrain   │ unknown   │ N/A                                      │ N/A
  remote_debug │ cancelled │ job-5938269e-4a57-408c-af39-109970ac5c59 │ Dec 22
  tensorboard  │ unknown   │ N/A                                      │ N/A
  train        │ unknown   │ N/A                                      │ N/A
               ╵           ╵                                       
```

### Monitoring bakes

Use the following command to monitor your project's bakes:

```
$ apolo-flow bakes
```

This command will show the the ID, creation date, and the status of each bake on your project.

To see detailed info about a specific bake, use:

```
$ apolo-flow inspect <bake-id>
```

This will show which tasks were executed in this bake, their statuses, IDs, starting and completion time. You can also export a bake's graph by adding the `--output-graph` option and choosing the desired graph format (DOT or PDF).\
\
You can learn more about bake inspection [neuro-flow inspect](https://app.gitbook.com/s/-MMLOF\_FqiWBMcOdY8cj/cli#neuro-flow-inspect "mention").
{% endtab %}

{% tab title="Apolo Console" %}
You can view the list of your projects in the **Flows** tab:

![](<../../.gitbook/assets/image (142).png>)

Click on a flow's name to view the list of its live jobs and batch bakes:

![](<../../.gitbook/assets/image (141).png>)

You can view each job's and bake's details by clicking on their name.
{% endtab %}
{% endtabs %}
